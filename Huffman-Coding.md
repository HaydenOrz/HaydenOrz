# 哈夫曼编码

> 2024/07/30

### 为何而记（引子）

在逛论坛的时候发现一个比较有意思的帖子，题目是 40 亿个账号，在限制内存的情况下如何去重？

以每个账号都是一个无符号位整型计，40 亿账号需要 4\*4000000000 /1024/1024/1024 = 14.9G 内存，这显然占用内存太大了。对应解决方案是使用位图，其核心思路是使用 40 亿个比特（约 500M），每一个比特位代表一个账号是否存在，1 代表存在，0 代表不存在。举例： 10086 账号对应第 10086 位，如果第 10086 位为 1，则代表该账号已存在。

这种解决方案本质上是对账号进行重新编码，以达到数据压缩的目的，这让我想起了大学时期学到过的比较经典的数据压缩算法： 哈夫曼编码。

### 更短的编码来压缩文本

对一份文本文件进行压缩，可以对文本中出现的字符重新编码，让新的编码所占的空间小于原有编码。**这里的核心思路是针对该文本的字符编码只需要关心文本内出现的字符即可**。

例如有一串字符串： `hello world` ，使用 utf-8 编码需要 11 Byte 来表示也就是 88 位。现在我们针对这个字符串中出现的字符来定制一个码表：

| 字符 | space | h   | e   | l   | o   | w   | r   | d   |
| ---- | ----- | --- | --- | --- | --- | --- | --- | --- |
| 编码 | 0     | 1   | 10  | 11  | 100 | 101 | 110 | 111 |

根据这个码表重新编码的 `hello world` 就是 `1101111100010110011011111` 共 24 位。

### 高频率字符使用更短的编码

但是这还没达到最佳的压缩率，可以让出现频率更高的字符的编码排在前面，也即是出现频率更高的字符的编码越短，这样又可以省下几个 bit，`hello world` 中各字符的出现频率为 ：

| 字符 | l   | o   | space | h   | e   | w   | r   | d   |
| ---- | --- | --- | ----- | --- | --- | --- | --- | --- |
| 编码 | 3   | 2   | 1     | 1   | 1   | 1   | 1   | 1   |

优化后的码表为：

| 字符 | l   | o   | space | h   | e   | w   | r   | d   |
| ---- | --- | --- | ----- | --- | --- | --- | --- | --- |
| 编码 | 0   | 1   | 10    | 11  | 100 | 101 | 110 | 111 |

优化后 `hello world` 的编码为： `111000011010111100111` 共 21 位。

**现在新的问题出现了，从这串编码中无法解码出原本的文本**。以这串编码的前 5 位为例，我们无法分辨出，是 11 + 110 即 `h` + `e` ，还是 111 + 10 即 `d` + `空格` ，也就是说目前的编码是存在歧义的。

### 哈夫曼树

要对一段文本进行哈夫曼编码，首先要**统计出每个字符出现的频率**，然后基于这些字符出现的频率来构建哈夫曼树。

哈夫曼树的构建过程：

1. 将所有出现的字符都分别作为一个单独的叶子结点，其出现的频率为叶子结点的权值，并将所有节点放入一个队列中；
2. 每次都从队列中取出权值最小的两个节点；
3. 生成一个新的节点，取出的两个节点作为新节点的子节点，两个字节点的权值之和就是新节点的权值；
4. 然后将新节点加入到原有队列中；
5. 重复上述 2，3，4 步骤直到所节点都在同一颗树上；

<details>
<summary>构建过程图</summary>
<img src="assets/build-huffman-tree.svg"/>
</details>

最终形成的树就是哈夫曼树，然后将每个节点左边的边设置为 0，右边的边设置为 1。

<img src="assets/huffman-coding-tree.svg"/>

### 编码和解码

每个字符对应的编码就是从根节点到字符节点的路径，最终形成的码表为：

| 字符 | l   | o   | space | h    | e   | w   | r   | d   |
| ---- | --- | --- | ----- | ---- | --- | --- | --- | --- |
| 编码 | 00  | 010 | 0110  | 0111 | 100 | 101 | 110 | 111 |

这份码表有两个特征：

1. 出现频率越高的字符，其编码越短，这保证了最终该文本的编码较短
2. 没有任何一个字符的编码是其他字符的编码的前缀，也就是说 哈夫曼编码是一种前缀编码，这让哈夫曼编码的解码难度大大降低。

按照这个码表，`hello world` 的编码为 `011111000000011010111000111` 共 27 位。
由于其前缀编码的特征，解码起来也很方便，可以直接按位读取编码，并将当前读取到的编码放到一个 buffer 中，当 buffer 中暂存的编码片段等于码表中任一编码时，就讲其解码为相应字符。或者可以从霍夫曼树中解码，从根节点出发，以编码为路径一旦遇到字符节点就解码出一个字符，然后重新从根节点出发。实际上这两种方法的内核是一样的。

### 哈夫曼编码为何神奇？

从哈夫曼树的构建过程可以窥见一二

1. 每次挑选权值最小的节点，这意味着权值小的也就是频率低的字符的在树中的层级深，也就是编码较长，频率高的字符在树中更靠近根节点，也就是编码较短。
2. 每次都将权值加一起得到一个新节点，那么这保证了，哈夫曼编码是一种前缀编码，也就是不会存在歧义，如果要存在歧义，就要求某个字符节点的祖先节点中有字符节点，但是目前的算法就会保证字符节点的祖先节点一定都是非字符节点。

### 哈夫曼编码的小缺点

- 在编码后需要码表/哈夫曼树才能解码，所以在存储时需要连带着码表一起存储。

### More thoughts

行文至此，突然发现开头提到的使用位图压缩账号数据和使用哈夫曼编码压缩文本数据在某些方面是不一样的。

哈夫曼编码是无损压缩，它并不直接改变文本本身的信息熵，这是因为文本内部的字符和其分布概率并没有被改变，信息的熵仅由概率分布决定。

但是开头提到的使用位图改变了数据体本身所包含的信息，举例说明：如果原本使用数组来存储账号数据，那么数组本身相比于位图就多包含了账号排列顺序信息；再比如原本是在数据库表中存储所有的账号，那么相比于位图，数据库表中账号还关联了其他信息比如 id、用户名、密码等。也就是说位图相比于其他存储方式导致了信息熵的下降。
